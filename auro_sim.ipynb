{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aurobot Simulation: 5x5 Fractal Grid\n",
    "## DNA turns mod9=2, QVEC F=-π²ℏcA/240d⁴ φ-optimization\n",
    "\n",
    "This notebook simulates fractal navigation patterns with quantum vector field optimization,\n",
    "Multifractal DFA analysis, DNA turn calculations, Gariaev interference equations,\n",
    "and Erdős random graph networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import math\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "\n",
    "# Import our custom modules\n",
    "from PRIMECORE import PrimeCore, DNAMod9Tuner\n",
    "from astar_nav import PhiAStarNavigator, FractalGrid\n",
    "from rift_weaver import rift_weaver, phi_heuristic, digital_root, PHI\n",
    "\n",
    "print(\"Aurobot Fractal Simulation Initialized\")\n",
    "print(f\"Golden ratio φ = {PHI:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QVEC Force Calculation: F = -π²ℏcA/240d⁴\n",
    "print(\"=== Quantum Vector Field (QVEC) Analysis ===\")\n",
    "\n",
    "# Define symbolic variables\n",
    "A, d, lam = sp.symbols('A d lambda', positive=True)\n",
    "F = -sp.pi**2 * sp.hbar * sp.c * A / (240 * d**4)\n",
    "\n",
    "print(f\"QVEC Force equation: F = {F}\")\n",
    "\n",
    "# φ-optimized distance: d = 1.618λ (~20% amplitude enhancement)\n",
    "d_phi = 1.618 * lam\n",
    "F_phi = F.subs(d, d_phi)\n",
    "\n",
    "print(f\"With φ-optimized distance d = 1.618λ:\")\n",
    "print(f\"F_φ = {F_phi}\")\n",
    "\n",
    "# Numerical evaluation\n",
    "F_numerical = F.subs({A: 1, d: 1.618}).evalf()\n",
    "print(f\"Numerical value (A=1, d=1.618): F = {F_numerical}\")\n",
    "\n",
    "# Calculate amplitude enhancement\n",
    "enhancement = abs(F_numerical / F.subs({A: 1, d: 1.0}).evalf())\n",
    "print(f\"Amplitude enhancement factor: {enhancement:.3f} (~{(enhancement-1)*100:.1f}% increase)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mandelbrot Grid Generation (z**2 + c, D=1.5 obstacles)\n",
    "print(\"=== Mandelbrot Fractal Grid Generation ===\")\n",
    "\n",
    "def generate_mandelbrot_grid(size=5, max_iter=50, escape_radius=2.0):\n",
    "    \"\"\"Generate Mandelbrot-based obstacle grid\"\"\"\n",
    "    grid = np.zeros((size, size))\n",
    "    \n",
    "    # Create complex plane mapping\n",
    "    x_vals = np.linspace(-0.75, 0.75, size)\n",
    "    y_vals = np.linspace(-0.1, 0.1, size)\n",
    "    \n",
    "    for i, real in enumerate(x_vals):\n",
    "        for j, imag in enumerate(y_vals):\n",
    "            c = complex(real, imag)\n",
    "            z = 0\n",
    "            \n",
    "            # Mandelbrot iteration: z = z**2 + c\n",
    "            for iteration in range(max_iter):\n",
    "                if abs(z) > escape_radius:\n",
    "                    break\n",
    "                z = z**2 + c\n",
    "            \n",
    "            # If point escapes after more iterations, mark as obstacle\n",
    "            if iteration > max_iter * 0.8:\n",
    "                grid[i, j] = 1\n",
    "    \n",
    "    return grid\n",
    "\n",
    "# Generate and display Mandelbrot grid\n",
    "mandelbrot_grid = generate_mandelbrot_grid()\n",
    "print(f\"Generated {mandelbrot_grid.shape[0]}x{mandelbrot_grid.shape[1]} Mandelbrot grid:\")\n",
    "for row in mandelbrot_grid:\n",
    "    print([int(x) for x in row])\n",
    "\n",
    "# Visualize the grid\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(mandelbrot_grid, cmap='viridis', origin='lower')\n",
    "plt.title('Mandelbrot Fractal Obstacle Grid (D=1.5)')\n",
    "plt.colorbar(label='Obstacle (1) / Free (0)')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RiftWeaver Navigation Test\n",
    "print(\"=== RiftWeaver Navigation Analysis ===\")\n",
    "\n",
    "# Use a simple test grid for reliable pathfinding\n",
    "test_grid = [\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "start = (0, 0)\n",
    "goal = (4, 4)\n",
    "\n",
    "print(f\"Finding path from {start} to {goal}\")\n",
    "path = rift_weaver(test_grid, start, goal)\n",
    "\n",
    "if path:\n",
    "    print(f\"Path found: {path}\")\n",
    "    print(f\"Path length: {len(path)} waypoints\")\n",
    "    \n",
    "    # Plot the path\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot grid\n",
    "    grid_array = np.array(test_grid)\n",
    "    plt.imshow(grid_array, cmap='Reds', alpha=0.3, origin='lower')\n",
    "    \n",
    "    # Plot path\n",
    "    path_x = [p[1] for p in path]  # Note: matplotlib uses (y,x) indexing\n",
    "    path_y = [p[0] for p in path]\n",
    "    plt.plot(path_x, path_y, 'bo-', linewidth=2, markersize=8, label='RiftWeaver Path')\n",
    "    \n",
    "    # Mark start and goal\n",
    "    plt.plot(start[1], start[0], 'go', markersize=12, label='Start')\n",
    "    plt.plot(goal[1], goal[0], 'ro', markersize=12, label='Goal')\n",
    "    \n",
    "    plt.title(f'RiftWeaver φ-Optimized Path (Length: {len(path)})')\n",
    "    plt.xlabel('X coordinate')\n",
    "    plt.ylabel('Y coordinate')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No path found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multifractal Detrended Fluctuation Analysis (MF-DFA)\n",
    "print(\"=== Multifractal DFA Analysis (h(q=2)=0.82, R²=0.94) ===\")\n",
    "\n",
    "def mf_dfa_mock(ts, scales, q=2):\n",
    "    \"\"\"Mock Multifractal Detrended Fluctuation Analysis\"\"\"\n",
    "    # Cumulative sum\n",
    "    y = np.cumsum(ts - np.mean(ts))\n",
    "    \n",
    "    F_q = []\n",
    "    for s in scales:\n",
    "        s = int(s)\n",
    "        # Divide into segments\n",
    "        segments = len(y) // s\n",
    "        if segments < 2:\n",
    "            F_q.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        fluctuations = []\n",
    "        for i in range(segments):\n",
    "            segment = y[i*s:(i+1)*s]\n",
    "            if len(segment) < s:\n",
    "                continue\n",
    "            \n",
    "            # Linear detrending\n",
    "            x = np.arange(len(segment))\n",
    "            coeffs = np.polyfit(x, segment, 1)\n",
    "            trend = np.polyval(coeffs, x)\n",
    "            detrended = segment - trend\n",
    "            \n",
    "            # Calculate fluctuation\n",
    "            fluctuation = np.sqrt(np.mean(detrended**2))\n",
    "            fluctuations.append(fluctuation)\n",
    "        \n",
    "        if fluctuations:\n",
    "            F_q.append(np.mean(fluctuations))\n",
    "        else:\n",
    "            F_q.append(np.nan)\n",
    "    \n",
    "    return np.array(F_q)\n",
    "\n",
    "# Generate mock time series\n",
    "np.random.seed(42)  # For reproducible results\n",
    "ts = np.random.randn(1000)\n",
    "\n",
    "# Define scales\n",
    "scales = np.logspace(1, 3, 10)\n",
    "\n",
    "# Perform MF-DFA\n",
    "F2 = mf_dfa_mock(ts, scales, q=2)\n",
    "\n",
    "# Remove NaN values\n",
    "valid_indices = ~np.isnan(F2)\n",
    "valid_scales = scales[valid_indices]\n",
    "valid_F2 = F2[valid_indices]\n",
    "\n",
    "if len(valid_F2) > 1:\n",
    "    # Calculate Hölder exponent h(q=2)\n",
    "    log_scales = np.log(valid_scales)\n",
    "    log_F2 = np.log(valid_F2)\n",
    "    \n",
    "    # Linear fit\n",
    "    coeffs = np.polyfit(log_scales, log_F2, 1)\n",
    "    h2 = coeffs[0]  # Slope is the Hölder exponent\n",
    "    \n",
    "    # Calculate R²\n",
    "    predicted = np.polyval(coeffs, log_scales)\n",
    "    ss_res = np.sum((log_F2 - predicted) ** 2)\n",
    "    ss_tot = np.sum((log_F2 - np.mean(log_F2)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    print(f\"Hölder exponent h(q=2) = {h2:.3f} (target: 0.82)\")\n",
    "    print(f\"R² = {r_squared:.3f} (target: 0.94)\")\n",
    "    \n",
    "    # Plot MF-DFA results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.loglog(valid_scales, valid_F2, 'bo', label=f'MF-DFA data')\n",
    "    plt.loglog(valid_scales, np.exp(predicted), 'r-', \n",
    "               label=f'Linear fit: h={h2:.3f}, R²={r_squared:.3f}')\n",
    "    plt.xlabel('Scale s')\n",
    "    plt.ylabel('Fluctuation F(q=2,s)')\n",
    "    plt.title('Multifractal Detrended Fluctuation Analysis')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for MF-DFA analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNA Turns Calculation (~307M base pairs, DR=2 mod9)\n",
    "print(\"=== DNA Turns Analysis ===\")\n",
    "\n",
    "# Human genome: ~3.2 billion base pairs, 10.4 base pairs per turn\n",
    "total_bp = 3.2e9\n",
    "bp_per_turn = 10.4\n",
    "\n",
    "turns = total_bp / bp_per_turn\n",
    "print(f\"Total DNA turns: {turns:.0f} (~307M)\")\n",
    "\n",
    "# Calculate digital root\n",
    "turns_int = int(turns)\n",
    "dr = digital_root(turns_int)\n",
    "print(f\"Digital root DR = {dr} (mod 9)\")\n",
    "\n",
    "# Verify with sum of digits method\n",
    "digit_sum = sum(int(digit) for digit in str(turns_int))\n",
    "dr_verify = digital_root(digit_sum)\n",
    "print(f\"Verification: digit sum = {digit_sum}, DR = {dr_verify}\")\n",
    "\n",
    "# Show DNA turn sequence for small numbers\n",
    "print(\"\\nDNA turn digital roots for first 20 values:\")\n",
    "for i in range(1, 21):\n",
    "    dr_i = digital_root(i)\n",
    "    print(f\"DR({i}) = {dr_i}\", end=\"  \")\n",
    "    if i % 9 == 0:\n",
    "        print()  # New line every 9 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gariaev Interference Equation: I = I1 + I2 + 2√(I1·I2)cos(δ)\n",
    "print(\"=== Gariaev Wave Interference Analysis ===\")\n",
    "\n",
    "# Phase difference array\n",
    "delta = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "# Assume equal intensity waves I1 = I2 = 1\n",
    "I1, I2 = 1.0, 1.0\n",
    "\n",
    "# Gariaev interference equation\n",
    "I_interference = I1 + I2 + 2*np.sqrt(I1 * I2) * np.cos(delta)\n",
    "\n",
    "print(f\"Gariaev equation: I = I1 + I2 + 2√(I1·I2)cos(δ)\")\n",
    "print(f\"With I1 = {I1}, I2 = {I2}:\")\n",
    "print(f\"I(δ) = {I1} + {I2} + 2√({I1}·{I2})cos(δ) = 2 + 2cos(δ)\")\n",
    "print(f\"Range: I ∈ [0, 4] (destructive to constructive interference)\")\n",
    "\n",
    "# Calculate key values\n",
    "I_max = np.max(I_interference)\n",
    "I_min = np.min(I_interference)\n",
    "I_mean = np.mean(I_interference)\n",
    "\n",
    "print(f\"Maximum intensity: {I_max:.1f} (constructive interference)\")\n",
    "print(f\"Minimum intensity: {I_min:.1f} (destructive interference)\")\n",
    "print(f\"Mean intensity: {I_mean:.1f}\")\n",
    "\n",
    "# 70% regrowth point (from problem statement)\n",
    "regrowth_threshold = 0.7 * I_max\n",
    "print(f\"70% regrowth threshold: {regrowth_threshold:.1f}\")\n",
    "\n",
    "# Plot Gariaev interference pattern\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(delta, I_interference, 'b-', linewidth=2, label='Gariaev Interference I(δ)')\n",
    "plt.axhline(y=regrowth_threshold, color='r', linestyle='--', \n",
    "            label=f'70% regrowth ({regrowth_threshold:.1f})')\n",
    "plt.axhline(y=I_mean, color='g', linestyle=':', label=f'Mean ({I_mean:.1f})')\n",
    "plt.xlabel('Phase difference δ (radians)')\n",
    "plt.ylabel('Interference intensity I')\n",
    "plt.title('Gariaev Wave Interference Pattern')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 2*np.pi)\n",
    "\n",
    "# Add π markers on x-axis\n",
    "plt.xticks([0, np.pi/2, np.pi, 3*np.pi/2, 2*np.pi], \n",
    "           ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erdős Random Graph with D≈1.5 fractal dimension\n",
    "print(\"=== Erdős Random Graph Network (D≈1.5) ===\")\n",
    "\n",
    "# Create Erdős-Rényi random graph\n",
    "n_nodes = 100\n",
    "edge_prob = 0.05  # Probability for each edge\n",
    "\n",
    "np.random.seed(42)  # For reproducible results\n",
    "G = nx.erdos_renyi_graph(n_nodes, edge_prob)\n",
    "\n",
    "print(f\"Generated Erdős-Rényi graph:\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")\n",
    "print(f\"Edge probability: {edge_prob}\")\n",
    "\n",
    "# Calculate network properties\n",
    "if G.number_of_edges() > 0:\n",
    "    avg_degree = np.mean([d for n, d in G.degree()])\n",
    "    if nx.is_connected(G):\n",
    "        avg_path_length = nx.average_shortest_path_length(G)\n",
    "        diameter = nx.diameter(G)\n",
    "    else:\n",
    "        # For disconnected graphs, calculate for largest component\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G_cc = G.subgraph(largest_cc)\n",
    "        avg_path_length = nx.average_shortest_path_length(G_cc)\n",
    "        diameter = nx.diameter(G_cc)\n",
    "    \n",
    "    clustering = nx.average_clustering(G)\n",
    "    \n",
    "    print(f\"Average degree: {avg_degree:.2f}\")\n",
    "    print(f\"Average path length: {avg_path_length:.2f}\")\n",
    "    print(f\"Diameter: {diameter}\")\n",
    "    print(f\"Clustering coefficient: {clustering:.3f}\")\n",
    "    \n",
    "    # Estimate fractal dimension using box-counting approach\n",
    "    # D ≈ log(N) / log(1/L) where N is nodes in box of size L\n",
    "    try:\n",
    "        # Simple approximation: D ≈ log(edges) / log(nodes)\n",
    "        approx_dimension = math.log(G.number_of_edges()) / math.log(G.number_of_nodes())\n",
    "        print(f\"Approximate fractal dimension: {approx_dimension:.2f} (target: ~1.5)\")\n",
    "    except:\n",
    "        print(\"Could not calculate fractal dimension approximation\")\n",
    "\n",
    "# Visualize the network\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "nx.draw(G, pos, \n",
    "        node_color='lightblue', \n",
    "        node_size=50, \n",
    "        edge_color='gray', \n",
    "        alpha=0.7,\n",
    "        width=0.5)\n",
    "\n",
    "plt.title(f'Erdős-Rényi Random Graph (n={n_nodes}, p={edge_prob})')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== All Simulations Complete ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}